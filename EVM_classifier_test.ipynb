{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the extreme value machine classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing dependencies and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import bayes_classifier\n",
    "from classifiers import MEVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "df = pd.read_csv('./dataset/data.csv')\n",
    "data = df.drop(['person_ID', 'frame', 'stream', 'sequance'], axis=1)\n",
    "target = df[\"person_ID\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For conducting all the experiments in this section the ChokePoint Dataset was used by first having the data processed by the facenet neural network to produce a data frame of the embedings of all the faces alongside some identifiable information like the person_ID, frame, stream and sequance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to use the protocol suggested by the authors of the dataset for the verification, in which the data is devided into two groups G1 and G2, each group will play the turn of training set and evaluation set in turn. for more information please refer to http://arma.sourceforge.net/chokepoint/\n",
    "\n",
    "and we have decided to use case study 1 which is concerned with:\n",
    "1. indoor scenes only\n",
    "2. short time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_streams = [\"P1E_S1_C1\", \"P1E_S2_C2\", \"P1L_S1_C1\", \"P1L_S2_C2\"]\n",
    "G1_sequence = [\"P1E_S1\", \"P1E_S2\",\"P1L_S1\", \"P1L_S2\"]\n",
    "G2_streams = [\"P1E_S3_C3\", \"P1L_S3_C3\", \"P1E_S4_C1\", \"P1L_S4_C1\"]\n",
    "G2_sequence = [\"P1E_S3\", \"P1L_S3\",\"P1E_S4\", \"P1L_S4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_data = df[df[\"stream\"].isin(G1_streams)]\n",
    "G1_indices = G1_data.index[G1_data[\"stream\"].isin(G1_streams)]\n",
    "G1_sequance_ind = [G1_data.index[G1_data[\"sequance\"] == sequence] \n",
    "                   for sequence in G1_sequence]\n",
    "G2_data = df[df[\"stream\"].isin(G2_streams)]\n",
    "G2_indices = G2_data.index[G2_data[\"stream\"].isin(G2_streams)]\n",
    "G2_sequance_ind = [G2_data.index[G2_data[\"sequance\"] == sequence] \n",
    "                   for sequence in G2_sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of indices is prepared for cross validation, it contains 32 pairs of sets of indices where each sequance of G1 will be used as training and tested against each sequance of G2 and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_G1 = [(G1_S, G2_S) for G1_S in G1_sequance_ind for G2_S in G2_sequance_ind]\n",
    "cv_G2 = [(G2_S, G1_S) for G1_S in G1_sequance_ind for G2_S in G2_sequance_ind]\n",
    "cv = cv_G1 + cv_G2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: exploring the accuracy of the classifier when trained on all classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test the classifier is tuned according to the protocol discussed above, to find the best accuracy it can reach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better suite the data to the application that we are working on it was decided that the classifier should be trained on data only from one sequence at a time rather than the entire group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the EVM classifier we are searching to tune 3 parameters (tailsize, cover_threshold, distance_multiplier) and due to how computationally expensive it would be to search all possible combinations, the parameters will be tuned one at a time, for example parameter 1 will be searched while parameter 2 and 3 are set to the defaults and then parameter 2 will be searched with parameter 1 set to the previous found value while parameter 3 is set to the default and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"cover_threshold\": 10 ** np.linspace(-2, 0.5, 40),\n",
    "              \"tailsize\": np.linspace(0, 800, 40, dtype=int),              \n",
    "              \"distance_multiplier\": 10 ** np.linspace(-2, 0.5, 40)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = {}\n",
    "for parameter, values in param_grid.items():\n",
    "    candidates[parameter] = values\n",
    "    grid_g = GridSearchCV(MEVM(), candidates, \n",
    "                          cv=cv, refit=False, n_jobs=16)\n",
    "    grid_g.fit(data, target)\n",
    "    candidates[parameter] = [grid_g.best_params_[parameter]]\n",
    "\n",
    "scores_g = grid_g.cv_results_.get('mean_test_score').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cover_threshold': 1.1253355826007645, 'distance_multiplier': 0.7227271320676177, 'tailsize': 800}\n",
      "accuracy = 0.9856309396604963\n"
     ]
    }
   ],
   "source": [
    "print(grid_g.best_params_)\n",
    "print('accuracy =', grid_g.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: exploring the accuracy of the classifier when a subset of the classes is unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test a third of the classes are replced by a choosen label as unknowns, within the classifier implementation any data with this labe is not used for training and the classifier produces this label when the probability of all the classes is less than a determined threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability theshold is passed as a parameter to the classifier when it is initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = df.person_ID.unique()\n",
    "unknowns= IDs[:len(IDs)//3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing the target list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_novel = df.copy()\n",
    "for unknown in unknowns:\n",
    "    df_novel[\"person_ID\"].replace({unknown : 2}, inplace=True)\n",
    "targets_novel = df_novel[\"person_ID\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test we are searching to find the optimal value for the novelty parameter given the parameters we have found in the previous test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "for parameter, value in grid_g.best_params_.items():\n",
    "    param_grid[parameter] = [value]\n",
    "novelty = 10 ** np.linspace(-2, 0, 30)\n",
    "param_grid[\"novelty\"] = novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_novel = GridSearchCV(MEVM(), param_grid, \n",
    "                          cv=cv, refit=False, n_jobs=16)\n",
    "grid_novel.fit(data, targets_novel)\n",
    "\n",
    "scores_novel = grid_novel.cv_results_.get('mean_test_score').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cover_threshold': 1.1253355826007645, 'distance_multiplier': 0.7227271320676177, 'novelty': 0.8531678524172805, 'tailsize': 800}\n",
      "accuracy = 0.930301391836054\n"
     ]
    }
   ],
   "source": [
    "print(grid_novel.best_params_)\n",
    "print('accuracy =', grid_novel.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further more the classifier is tested again with the same parameters but with different subset of the classes as unknowns to check if it provides similar results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns_test= IDs[-len(IDs)//3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_novel_test = df.copy()\n",
    "for unknown in unknowns_test:\n",
    "    df_novel_test[\"person_ID\"].replace({unknown : 2}, inplace=True)\n",
    "targets_novel_test = df_novel_test[\"person_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "for parameter, value in grid_novel.best_params_.items():\n",
    "    param_grid[parameter] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_novel_test = GridSearchCV(MEVM(), param_grid, \n",
    "                               cv=cv, refit=False, n_jobs=16)\n",
    "grid_novel_test.fit(data, targets_novel_test)\n",
    "\n",
    "scores_novel_test = grid_novel_test.cv_results_.get('mean_test_score').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9020545787314297\n"
     ]
    }
   ],
   "source": [
    "print('accuracy =', grid_novel_test.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 3:exploring the accuracy of the classifier when a subset of the classes is unknown while tracking the person being recognized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test we combine all the predictions from a given sequence for an individual to estimate multiple predictions of a tracked subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore we use the \"n\" parameter to limit the number of samples used for training and the \"shuffle\" parameter to shuffle the data for a given class before using the first n samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"n\" and \"shuffle\" parameters together simulate choosing n random samples of a given sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_novel_tracks = df.copy()\n",
    "data_novel_tracks['tracks'] = (data_novel_tracks['person_ID'].astype(str) + \n",
    "                               data_novel_tracks['sequance'])\n",
    "for unknown in unknowns:\n",
    "    data_novel_tracks[\"person_ID\"].replace({unknown : 2}, inplace=True)\n",
    "targets_novel_tracks = data_novel_tracks[\"person_ID\"]\n",
    "data_novel_tracks = data_novel_tracks.drop(['person_ID', 'frame', \n",
    "                                            'stream', 'sequance'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of training samples is limited to n samples it is important that all parameters are tuned again and thus for this test all three parameters will be tuned again alongside the novelty parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important parameter to retune is the tailsize (number of negative samples used to train the EVM), as it was observed that the number of negative samples needed is highly affected by the number of samples used tto train the EVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"cover_threshold\": 10 ** np.linspace(-2, 0.5, 40),              \n",
    "              \"tailsize\": np.linspace(0, 70, 40, dtype=int),              \n",
    "              \"distance_multiplier\": 10 ** np.linspace(-2, 0.5, 40),\n",
    "              \"novelty\": 10 ** np.linspace(-2, 0, 40)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = {\"n\":[35], \"shuffle\":[True], \"novelty\":[0.5],\n",
    "              \"cover_threshold\":[grid_g.best_params_[\"cover_threshold\"]]}\n",
    "for parameter, values in param_grid.items():\n",
    "    candidates[parameter] = values\n",
    "    grid_novel_tracks = GridSearchCV(MEVM(), candidates, \n",
    "                          cv=cv, refit=False, n_jobs=16)\n",
    "    grid_novel_tracks.fit(data_novel_tracks, targets_novel_tracks)\n",
    "    candidates[parameter] = [grid_novel_tracks.best_params_[parameter]]\n",
    "\n",
    "scores_novel_tracks = grid_novel_tracks.cv_results_.get('mean_test_score').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cover_threshold': 1.7522244804127838, 'distance_multiplier': 0.7227271320676177, 'n': 35, 'novelty': 0.5541020330009492, 'shuffle': True, 'tailsize': 70}\n",
      "accuracy = 0.9908661750936569\n"
     ]
    }
   ],
   "source": [
    "print(grid_novel_tracks.best_params_)\n",
    "print('accuracy =', grid_novel_tracks.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The classifier is tested again with the same parameters but with different subset of the classes as unknowns to check if it provides similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_novel_tracks_test = df.copy()\n",
    "data_novel_tracks_test['tracks'] = (data_novel_tracks_test['person_ID'].astype(str) + \n",
    "                                    data_novel_tracks_test['sequance'])\n",
    "for unknown in unknowns_test:\n",
    "    data_novel_tracks_test[\"person_ID\"].replace({unknown : 2}, inplace=True)\n",
    "targets_novel_tracks_test = data_novel_tracks_test[\"person_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "for parameter, value in grid_novel_tracks.best_params_.items():\n",
    "    param_grid[parameter] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_novel_tracks_test = GridSearchCV(MEVM(), param_grid,\n",
    "                                      cv=cv, refit=False, n_jobs=16)\n",
    "grid_novel_tracks_test.fit(data_novel_tracks, targets_novel_tracks_test)\n",
    "\n",
    "scores_novel_tracks_test = grid_novel_tracks_test.cv_results_.get('mean_test_score').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9601887604692256\n"
     ]
    }
   ],
   "source": [
    "print('accuracy =', grid_novel_tracks_test.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
