{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring The support vector machine classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing dependencies and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "df = pd.read_csv('./dataset/data.csv')\n",
    "data = df.drop(['person_ID', 'frame', 'stream', 'sequance'], axis=1)\n",
    "target = df[\"person_ID\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For conducting all the experiments in this section the ChokePoint Dataset was used by first having the data processed by the facenet neural network to produce a data frame of the embedings of all the faces alongside some identifiable information like the person_ID, frame, stream and sequance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to use the protocol suggested by the authors of the dataset for the verification, in which the data is devided into two groups G1 and G2, each group will play the turn of training set and evaluation set in turn. for more information please refer to http://arma.sourceforge.net/chokepoint/\n",
    "\n",
    "and we have decided to use case study 1 which is concerned with:\n",
    "1. indoor scenes only\n",
    "2. short time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_streams = [\"P1E_S1_C1\", \"P1E_S2_C2\", \"P1L_S1_C1\", \"P1L_S2_C2\"]\n",
    "G1_sequence = [\"P1E_S1\", \"P1E_S2\",\"P1L_S1\", \"P1L_S2\"]\n",
    "G2_streams = [\"P1E_S3_C3\", \"P1L_S3_C3\", \"P1E_S4_C1\", \"P1L_S4_C1\"]\n",
    "G2_sequence = [\"P1E_S3\", \"P1L_S3\",\"P1E_S4\", \"P1L_S4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_data = df[df[\"stream\"].isin(G1_streams)]\n",
    "G1_indices = G1_data.index[G1_data[\"stream\"].isin(G1_streams)]\n",
    "G1_sequance_ind = [G1_data.index[G1_data[\"sequance\"] == sequence] \n",
    "                   for sequence in G1_sequence]\n",
    "G2_data = df[df[\"stream\"].isin(G2_streams)]\n",
    "G2_indices = G2_data.index[G2_data[\"stream\"].isin(G2_streams)]\n",
    "G2_sequance_ind = [G2_data.index[G2_data[\"sequance\"] == sequence] \n",
    "                   for sequence in G2_sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of indices is prepared for cross validation, it contains 32 pairs of sets of indices where each sequance of G1 will be used as training and tested against each sequance of G2 and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_G1 = [(G1_S, G2_S) for G1_S in G1_sequance_ind for G2_S in G2_sequance_ind]\n",
    "cv_G2 = [(G2_S, G1_S) for G1_S in G1_sequance_ind for G2_S in G2_sequance_ind]\n",
    "cv = cv_G1 + cv_G2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: exploring the accuracy of the classifier when trained on all classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test the classifier is tuned according to the protocol discussed above, to find the best accuracy it can reach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better suite the data to the application that we are working on it was decided that the classifier should be trained on data only from one sequence at a time rather than the entire group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C parameter is sampled from a linear function, while the gamma parameter is sampled from an exponential function and they are tested using three different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5.0, 'gamma': 1.0102862550356189, 'kernel': 'rbf'}\n",
      "accuracy = 0.9879507552795811\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': np.linspace(0.05, 5, 10), \n",
    "              'gamma': 10 ** np.linspace(0.01, 0, 10),\n",
    "              'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid_g = GridSearchCV(SVC(),param_grid,refit=False, n_jobs=16, cv=cv)\n",
    "grid_g.fit(data, target)\n",
    "\n",
    "scores_g = grid_g.cv_results_.get('mean_test_score').tolist()\n",
    "\n",
    "print(grid_g.best_params_)\n",
    "print('accuracy =', grid_g.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
